\newpage
\toclessheading{Abstract}

Effective evaluation of teaching is essential for educational quality assurance, yet conventional approaches such as student feedback often suffer from subjectivity, bias, and inconsistency. This motivated our hypothesis that objective, data-driven analysis of multimodal classroom interactions can provide a more reliable measure of pedagogical effectiveness.
To test this hypothesis, we designed a system that analyzes classroom video, audio, and transcripts to capture multiple dimensions of teaching. Visual data were processed to extract teacher movement and engagement patterns, audio data were analyzed for prosody and vocal delivery, and linguistic data were examined for discourse clarity and structure. Logistic regression models were then applied to predict instructional outcomes.
The results demonstrate that while linguistic features alone offered the strongest unimodal performance at 67.0\% accuracy, integration of all modalities significantly improved predictive power. The multimodal system achieved 71.33\% accuracy, showed greater cross-validation stability, and reached an area under the curve of 0.796. These findings confirm our hypothesis that multimodal integration captures complementary aspects of pedagogy that single modalities cannot fully represent.
This work positions multimodal learning analytics as a scalable, objective alternative to feedback, enabling future automated systems for teaching evaluation.